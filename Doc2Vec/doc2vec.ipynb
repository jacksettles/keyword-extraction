{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276b771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johnt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from docx import Document\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a388325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(file_path, patent_start=r'^\\s*US[0-9A-Z]*$'):\n",
    "    doc = Document(file_path)\n",
    "    labels = []\n",
    "    patents = []\n",
    "    current_patent_text = []\n",
    "    \n",
    "    for i, paragraph in enumerate(doc.paragraphs):\n",
    "        if re.search(patent_start, paragraph.text):\n",
    "            labels.append(paragraph.text)\n",
    "            if current_patent_text:\n",
    "                patents.append('\\n'.join(current_patent_text))\n",
    "            current_patent_text = []\n",
    "        else:\n",
    "            # If not a patent start, add the paragraph text to the current patent text\n",
    "            current_patent_text.append(paragraph.text)\n",
    "            \n",
    "    # Add the last patent text\n",
    "    if current_patent_text:\n",
    "        patents.append('\\n'.join(current_patent_text))\n",
    "\n",
    "    return patents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b5e7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.append('may')\n",
    "    stop_words = set(stop_words)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14eec43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents, labels = read_doc(r'C:\\Users\\johnt\\Downloads\\20240106021625210-AMD (2).docx')\n",
    "for i in range(len(patents)):\n",
    "    patents[i] = preprocess_text(patents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f22c826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=doc.split(), tags=[label]) for label, doc in zip(labels, patents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4669afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=20)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b87faeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_vectors = [model.infer_vector(doc.words) for doc in tagged_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03eb485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_documents = [model.dv.most_similar([inferred_vector], topn=5) for inferred_vector in inferred_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d14aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "keywords_per_doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "85a8cc80",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_id, inferred_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inferred_vectors):\n\u001b[0;32m      2\u001b[0m     word_weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdv[doc_id]\n\u001b[1;32m----> 4\u001b[0m     sorted_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_to_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[82], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_id, inferred_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inferred_vectors):\n\u001b[0;32m      2\u001b[0m     word_weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdv[doc_id]\n\u001b[1;32m----> 4\u001b[0m     sorted_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m word: \u001b[43mword_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_to_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "for doc_id, inferred_vector in enumerate(inferred_vectors):\n",
    "    word_weights = model.dv[doc_id]\n",
    "\n",
    "    sorted_words = sorted(model.wv.index_to_key, key=lambda word: word_weights[model.wv.key_to_index[word]], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0109f170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' US8053849B2', [' US8053849B2', ' US8753943B2', ' US8445975B2'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_per_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9885c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
